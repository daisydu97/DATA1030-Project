{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27820, 8)\n",
      "Index(['country', 'year', 'sex', 'age', 'population', 'suicides/100k pop',\n",
      "       'gdp_per_capita ($)', 'generation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Suicide Rate ML.csv')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['country', 'year', 'sex', 'age', 'population','gdp_per_capita ($)', 'generation']\n",
    "label = 'suicides/100k pop'\n",
    "y = df[label]\n",
    "X = df.drop(columns=[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML pipeline\n",
    "\n",
    "Ridge - Lecture 14 <br>\n",
    "Random Forest Regression - Lecture 18 <br>\n",
    "SVM rbf Regression - Lecture 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_ftrs = ['population', 'gdp_per_capita ($)']\n",
    "onehot_ftrs = ['country', 'sex', 'generation']\n",
    "ordinal_ftrs = ['age']\n",
    "minmax_ftrs = ['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_ridge(X,y,random_state,n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state = random_state)\n",
    "    best_alphas = []\n",
    "    test_scores = []\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other.iloc[train_index.tolist()], X_other.iloc[CV_index.tolist()]\n",
    "        y_train, y_CV = y_other.iloc[train_index.tolist()], y_other.iloc[CV_index.tolist()]\n",
    "        \n",
    "        ss = StandardScaler()\n",
    "        X_train_ss = ss.fit_transform(X_train[standard_ftrs])\n",
    "        X_train_ss = pd.DataFrame(X_train_ss, columns = standard_ftrs)\n",
    "        X_c_ss = ss.transform(X_CV[standard_ftrs])\n",
    "        X_c_ss = pd.DataFrame(X_c_ss, columns = standard_ftrs)\n",
    "        X_t_ss = ss.transform(X_test[standard_ftrs])\n",
    "        X_t_ss = pd.DataFrame(X_t_ss, columns = standard_ftrs)\n",
    "        \n",
    "        ohe = OneHotEncoder(sparse = False, categories='auto')\n",
    "        X_train_ohe = ohe.fit_transform(X_train[onehot_ftrs])\n",
    "        X_train_ohe = pd.DataFrame(X_train_ohe, columns = ohe.get_feature_names())\n",
    "        X_c_ohe = ohe.transform(X_CV[onehot_ftrs])\n",
    "        X_c_ohe = pd.DataFrame(X_c_ohe, columns = ohe.get_feature_names())\n",
    "        X_t_ohe = ohe.transform(X_test[onehot_ftrs])\n",
    "        X_t_ohe = pd.DataFrame(X_t_ohe, columns = ohe.get_feature_names())\n",
    "        \n",
    "        oe = OrdinalEncoder(categories = [['5-14 years','15-24 years', '25-34 years',\n",
    "                                       '35-54 years','55-74 years','75+ years']])\n",
    "        X_train_oe = oe.fit_transform(X_train[ordinal_ftrs])\n",
    "        X_train_oe = pd.DataFrame(X_train_oe, columns = ordinal_ftrs)\n",
    "        X_c_oe = oe.transform(X_CV[ordinal_ftrs])\n",
    "        X_c_oe = pd.DataFrame(X_c_oe, columns = ordinal_ftrs)\n",
    "        X_t_oe = oe.transform(X_test[ordinal_ftrs])\n",
    "        X_t_oe = pd.DataFrame(X_t_oe, columns = ordinal_ftrs)\n",
    "        \n",
    "        mm = MinMaxScaler()\n",
    "        X_train_mm = mm.fit_transform(X_train[minmax_ftrs])\n",
    "        X_train_mm = pd.DataFrame(X_train_mm, columns = minmax_ftrs)\n",
    "        X_c_mm = mm.transform(X_CV[minmax_ftrs])\n",
    "        X_c_mm = pd.DataFrame(X_c_mm, columns = minmax_ftrs)\n",
    "        X_t_mm = mm.transform(X_test[minmax_ftrs])\n",
    "        X_t_mm = pd.DataFrame(X_t_mm, columns = minmax_ftrs)\n",
    "\n",
    "        X_train_ = pd.concat([X_train_mm, X_train_oe, X_train_ohe, X_train_ss], axis=1)\n",
    "        X_CV_ = pd.concat([X_c_mm, X_c_oe, X_c_ohe, X_c_ss], axis=1)\n",
    "        X_test_ = pd.concat([X_t_mm, X_t_oe, X_t_ohe, X_t_ss], axis=1)\n",
    "        \n",
    "        alpha = np.logspace(-16,1,100)\n",
    "        CV_score = []\n",
    "        regs = []\n",
    "        for a in alpha:\n",
    "            reg = Ridge(alpha = a)\n",
    "            reg.fit(X_train_, y_train)\n",
    "            CV_score.append(reg.score(X_CV_, y_CV))\n",
    "            regs.append(reg)\n",
    "            \n",
    "        best_alpha = alpha[np.argmax(CV_score)]\n",
    "        best_alphas.append(best_alpha)\n",
    "        \n",
    "        reg = regs[np.argmax(CV_score)]\n",
    "        test_scores.append(reg.score(X_test_,y_test))\n",
    "        \n",
    "    BA = best_alphas[np.argmax(test_scores)]\n",
    "    return BA, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 0 and best alpha = 10.0.\n",
      "Random state = 42 and best alpha = 2.056512308348643.\n",
      "Random state = 84 and best alpha = 10.0.\n",
      "Random state = 126 and best alpha = 6.734150657750801.\n",
      "Random state = 168 and best alpha = 8.302175681319735e-14.\n",
      "Random state = 210 and best alpha = 3.0538555088334123.\n",
      "Random state = 252 and best alpha = 4.534878508128592.\n",
      "Random state = 294 and best alpha = 2.205130739903041e-16.\n",
      "Random state = 336 and best alpha = 0.2848035868435793.\n",
      "Random state = 378 and best alpha = 1e-16.\n",
      "test accuracy score: 0.509 +/- 0.009\n"
     ]
    }
   ],
   "source": [
    "TS_ridge = []\n",
    "for i in range(10):\n",
    "    best_alpha, test_score = ML_pipeline_kfold_ridge(X, y, 42*i, 5)\n",
    "    TS_ridge.append(test_score)\n",
    "    print('Random state = {} and best alpha = {}.'.format(42*i, best_alpha))\n",
    "print('test accuracy score:', np.around(np.mean(TS_ridge),3), '+/-', np.around(np.std(TS_ridge),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_rf(X, y, random_state, n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state = random_state)\n",
    "    best_ds = []\n",
    "    test_scores = []\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    for train_index, CV_index in kf.split(X_other, y_other):\n",
    "        X_train, X_CV = X_other.iloc[train_index.tolist()], X_other.iloc[CV_index.tolist()]\n",
    "        y_train, y_CV = y_other.iloc[train_index.tolist()], y_other.iloc[CV_index.tolist()]\n",
    "        \n",
    "        ss = StandardScaler()\n",
    "        X_train_ss = ss.fit_transform(X_train[standard_ftrs])\n",
    "        X_train_ss = pd.DataFrame(X_train_ss, columns = standard_ftrs)\n",
    "        X_c_ss = ss.transform(X_CV[standard_ftrs])\n",
    "        X_c_ss = pd.DataFrame(X_c_ss, columns = standard_ftrs)\n",
    "        X_t_ss = ss.transform(X_test[standard_ftrs])\n",
    "        X_t_ss = pd.DataFrame(X_t_ss, columns = standard_ftrs)\n",
    "        \n",
    "        ohe = OneHotEncoder(sparse = False, categories='auto')\n",
    "        X_train_ohe = ohe.fit_transform(X_train[onehot_ftrs])\n",
    "        X_train_ohe = pd.DataFrame(X_train_ohe, columns = ohe.get_feature_names())\n",
    "        X_c_ohe = ohe.transform(X_CV[onehot_ftrs])\n",
    "        X_c_ohe = pd.DataFrame(X_c_ohe, columns = ohe.get_feature_names())\n",
    "        X_t_ohe = ohe.transform(X_test[onehot_ftrs])\n",
    "        X_t_ohe = pd.DataFrame(X_t_ohe, columns = ohe.get_feature_names())\n",
    "        \n",
    "        oe = OrdinalEncoder(categories = [['5-14 years','15-24 years', '25-34 years',\n",
    "                                       '35-54 years','55-74 years','75+ years']])\n",
    "        X_train_oe = oe.fit_transform(X_train[ordinal_ftrs])\n",
    "        X_train_oe = pd.DataFrame(X_train_oe, columns = ordinal_ftrs)\n",
    "        X_c_oe = oe.transform(X_CV[ordinal_ftrs])\n",
    "        X_c_oe = pd.DataFrame(X_c_oe, columns = ordinal_ftrs)\n",
    "        X_t_oe = oe.transform(X_test[ordinal_ftrs])\n",
    "        X_t_oe = pd.DataFrame(X_t_oe, columns = ordinal_ftrs)\n",
    "        \n",
    "        mm = MinMaxScaler()\n",
    "        X_train_mm = mm.fit_transform(X_train[minmax_ftrs])\n",
    "        X_train_mm = pd.DataFrame(X_train_mm, columns = minmax_ftrs)\n",
    "        X_c_mm = mm.transform(X_CV[minmax_ftrs])\n",
    "        X_c_mm = pd.DataFrame(X_c_mm, columns = minmax_ftrs)\n",
    "        X_t_mm = mm.transform(X_test[minmax_ftrs])\n",
    "        X_t_mm = pd.DataFrame(X_t_mm, columns = minmax_ftrs)\n",
    "\n",
    "        X_train_ = pd.concat([X_train_mm, X_train_oe, X_train_ohe, X_train_ss], axis=1)\n",
    "        X_CV_ = pd.concat([X_c_mm, X_c_oe, X_c_ohe, X_c_ss], axis=1)\n",
    "        X_test_ = pd.concat([X_t_mm, X_t_oe, X_t_ohe, X_t_ss], axis=1)\n",
    "        \n",
    "        depths = [depth for depth in range(7,16)]\n",
    "        splits = [split for split in range(3,12)]\n",
    "        ds = [(depth, split) for depth in depths for split in splits]\n",
    "        CV_score = []\n",
    "        clfs = []\n",
    "        for d, s in ds:\n",
    "            clf = RandomForestRegressor(n_estimators=100, random_state=random_state,\n",
    "                                         max_depth=d, min_samples_split=s)\n",
    "            clf.fit(X_train_, y_train)\n",
    "            CV_score.append(clf.score(X_CV_, y_CV))\n",
    "            clfs.append(clf)\n",
    "        best_d = ds[np.argmax(CV_score)][0]\n",
    "        best_s = ds[np.argmax(CV_score)][1]\n",
    "        best_ds.append((best_d, best_s))\n",
    "        clf = clfs[np.argmax(CV_score)]\n",
    "        test_scores.append(clf.score(X_test_,y_test))\n",
    "    DS = best_ds[np.argmax(test_scores)]\n",
    "    return DS, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 0, best max_depth = 15, and best min_samples_split = 5.\n",
      "Random state = 42, best max_depth = 15, and best min_samples_split = 3.\n",
      "Random state = 84, best max_depth = 15, and best min_samples_split = 3.\n",
      "Random state = 126, best max_depth = 15, and best min_samples_split = 5.\n",
      "Random state = 168, best max_depth = 15, and best min_samples_split = 3.\n",
      "Random state = 210, best max_depth = 15, and best min_samples_split = 6.\n",
      "Random state = 252, best max_depth = 15, and best min_samples_split = 4.\n",
      "Random state = 294, best max_depth = 15, and best min_samples_split = 4.\n",
      "Random state = 336, best max_depth = 15, and best min_samples_split = 4.\n",
      "Random state = 378, best max_depth = 15, and best min_samples_split = 4.\n",
      "test accuracy score: 0.742 +/- 0.015\n"
     ]
    }
   ],
   "source": [
    "TS_rf = []\n",
    "for i in range(10):\n",
    "    best_ds, test_score = ML_pipeline_kfold_rf(X, y, 42*i,5)\n",
    "    TS_rf.append(test_score)\n",
    "    print('Random state = {}, best max_depth = {}, and best min_samples_split = {}.'.format(42*i,\n",
    "                                                                                             best_ds[0], best_ds[1]))\n",
    "print('test accuracy score:', np.around(np.mean(TS_rf),3), '+/-', np.around(np.std(TS_rf),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_svr(X, y, random_state, n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state = random_state)\n",
    "    best_gc = []\n",
    "    test_scores = []\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state=random_state) \n",
    "    \n",
    "    for train_index, CV_index in kf.split(X_other, y_other):\n",
    "        X_train, X_CV = X_other.iloc[train_index.tolist()], X_other.iloc[CV_index.tolist()]\n",
    "        y_train, y_CV = y_other.iloc[train_index.tolist()], y_other.iloc[CV_index.tolist()]\n",
    "        \n",
    "        ss = StandardScaler()\n",
    "        X_train_ss = ss.fit_transform(X_train[standard_ftrs])\n",
    "        X_train_ss = pd.DataFrame(X_train_ss, columns = standard_ftrs)\n",
    "        X_c_ss = ss.transform(X_CV[standard_ftrs])\n",
    "        X_c_ss = pd.DataFrame(X_c_ss, columns = standard_ftrs)\n",
    "        X_t_ss = ss.transform(X_test[standard_ftrs])\n",
    "        X_t_ss = pd.DataFrame(X_t_ss, columns = standard_ftrs)\n",
    "        \n",
    "        ohe = OneHotEncoder(sparse = False, categories='auto')\n",
    "        X_train_ohe = ohe.fit_transform(X_train[onehot_ftrs])\n",
    "        X_train_ohe = pd.DataFrame(X_train_ohe, columns = ohe.get_feature_names())\n",
    "        X_c_ohe = ohe.transform(X_CV[onehot_ftrs])\n",
    "        X_c_ohe = pd.DataFrame(X_c_ohe, columns = ohe.get_feature_names())\n",
    "        X_t_ohe = ohe.transform(X_test[onehot_ftrs])\n",
    "        X_t_ohe = pd.DataFrame(X_t_ohe, columns = ohe.get_feature_names())\n",
    "        \n",
    "        oe = OrdinalEncoder(categories = [['5-14 years','15-24 years', '25-34 years',\n",
    "                                       '35-54 years','55-74 years','75+ years']])\n",
    "        X_train_oe = oe.fit_transform(X_train[ordinal_ftrs])\n",
    "        X_train_oe = pd.DataFrame(X_train_oe, columns = ordinal_ftrs)\n",
    "        X_c_oe = oe.transform(X_CV[ordinal_ftrs])\n",
    "        X_c_oe = pd.DataFrame(X_c_oe, columns = ordinal_ftrs)\n",
    "        X_t_oe = oe.transform(X_test[ordinal_ftrs])\n",
    "        X_t_oe = pd.DataFrame(X_t_oe, columns = ordinal_ftrs)\n",
    "        \n",
    "        mm = MinMaxScaler()\n",
    "        X_train_mm = mm.fit_transform(X_train[minmax_ftrs])\n",
    "        X_train_mm = pd.DataFrame(X_train_mm, columns = minmax_ftrs)\n",
    "        X_c_mm = mm.transform(X_CV[minmax_ftrs])\n",
    "        X_c_mm = pd.DataFrame(X_c_mm, columns = minmax_ftrs)\n",
    "        X_t_mm = mm.transform(X_test[minmax_ftrs])\n",
    "        X_t_mm = pd.DataFrame(X_t_mm, columns = minmax_ftrs)\n",
    "\n",
    "        X_train_ = pd.concat([X_train_mm, X_train_oe, X_train_ohe, X_train_ss], axis=1)\n",
    "        X_CV_ = pd.concat([X_c_mm, X_c_oe, X_c_ohe, X_c_ss], axis=1)\n",
    "        X_test_ = pd.concat([X_t_mm, X_t_oe, X_t_ohe, X_t_ss], axis=1)\n",
    "        \n",
    "        cs = np.logspace(-3, 10, 13)\n",
    "        gammas = np.logspace(-9, 3, 13)\n",
    "        gc = [(gamma, c) for gamma in gammas for c in cs]\n",
    "        CV_score = []\n",
    "        clfs = []\n",
    "        for g, c in gc:\n",
    "            clf = SVR(gamma=g, C=c)\n",
    "            clf.fit(X_train_, y_train)\n",
    "            CV_score.append(clf.score(X_CV_, y_CV))\n",
    "            clfs.append(clf)\n",
    "        best_g = gc[np.argmax(CV_score)][0]\n",
    "        best_c = gc[np.argmax(CV_score)][1]\n",
    "        best_gc.append((best_g, best_c))\n",
    "        clf = clfs[np.argmax(CV_score)]\n",
    "    test_scores.append(clf.score(X_test_,y_test))\n",
    "    GC = best_gc[np.argmax(test_scores)]\n",
    "    return GC, test_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_svr = []\n",
    "for i in range(10):\n",
    "    best_gc, test_score = ML_pipeline_kfold_svr(X, y, 42*i, 5)\n",
    "    TS_svr.append(test_score)\n",
    "    print('Random state = {}, best gamma = {}, and best C = {}.'.format(42*i, \n",
    "                                                                         best_gc[0], best_gc[1]))\n",
    "\n",
    "print('test accuracy score:', np.around(np.mean(TS_svr),3), '+/-', np.around(np.std(TS_svr),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = 294)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=294)\n",
    "\n",
    "ds = [8, 5, 7, 9, 8]\n",
    "ss = [300, 363, 291, 201, 273]\n",
    "ind = 0\n",
    "for train_index, CV_index in kf.split(X_other, y_other):\n",
    "    X_train, X_CV = X_other.iloc[train_index.tolist()], X_other.iloc[CV_index.tolist()]\n",
    "    y_train, y_CV = y_other.iloc[train_index.tolist()], y_other.iloc[CV_index.tolist()]\n",
    "        \n",
    "    X_train_, X_CV_, X_test_ = preprocess(X_train, X_CV, X_test, random_state=294)\n",
    "\n",
    "    clf_rf = RandomForestClassifier(n_estimators=100, random_state=294, max_depth=ds[ind], min_samples_split=ss[ind])\n",
    "    clf_rf.fit(X_train_, y_train)\n",
    "    imp = clf_rf.feature_importances_\n",
    "    \n",
    "    print(imp)\n",
    "    plt.bar(range(len(imp)), imp)\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.title(\"Global Feature Importance - Random Forest Classifier\")\n",
    "    plt.xticks(range(len(imp)), proc_ftrs, rotation='vertical')\n",
    "    plt.savefig('../figures/random_forest_global_ftr_importance{}'.format(ind), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    ind += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
